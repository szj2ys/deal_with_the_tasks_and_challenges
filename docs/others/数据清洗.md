
`map、applymap、apply用法 <https://zhuanlan.zhihu.com/p/100064394>`__

`常用函数详解 <https://zhuanlan.zhihu.com/p/106724730>`__

## 行列转换

### T
```python
df.T
```

### stack和unstack
```python
stack和unstack
# The stack() method “compresses” a level in the DataFrame’s columns

```
运行下面的代码你就全明白了

先创建数据
```python
tuples = list(
     zip(
         *[
             ["bar", "bar", "baz", "baz", "foo", "foo", "qux", "qux"],
             ["one", "two", "one", "two", "one", "two", "one", "two"],
         ]
     )
 )
 

index = pd.MultiIndex.from_tuples(tuples, names=["first", "second"])

df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=["A", "B"])

df2 = df[:4]

df2.head()
```

stack操作
```python
stacked = df2.stack().to_frame()  # stack返回Series
stacked
```
unstack操作
>With a “stacked” DataFrame or Series (having a MultiIndex as the index), the inverse operation of stack() is unstack(), which by default unstacks the last level:
> 

```python
unstacked = stacked.unstack()  # unstack返回Dataframe
unstacked
```
#### 分别对不同的所有unstack

```python
stacked.unstack(1)
```

```python
stacked.unstack(1)
```


## 大小写转换
```python
df['name'].str.lower()
df['name'].str.upper()
```
## [数据移动](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html#pandas.DataFrame.shift)
[All the Pandas shift() you should know for data analysis](https://towardsdatascience.com/all-the-pandas-shift-you-should-know-for-data-analysis-791c1692b5e)

### 将数据往后移动

```python
# periods :转移时间数，可正可负，正为向前移动，负为向后移动
# axis:轴向
# fill_value:对产生的缺失值是否做补充

df.shift(periods=5, axis=0, fill_value=0)
```

## 替换

### 将priority列中的yes, no替换为布尔值True, False

```python
df['priority'] = df['priority'].map({'yes': True, 'no': False})
```


### 内容替换

```python
# 将animal列中的snake替换为python
df['animal'] = df['animal'].replace('snake', 'python')

df.replace({"b": "."}, {"b": np.nan})

# 使用正则替换
df.replace(r"\s*\.\s*", np.nan, regex=True)
df.replace({"b": r"\s*\.\s*"}, {"b": np.nan}, regex=True)
```

## 修改


### 修改列名`score`为`popularity`

```python
df.rename(columns={'score':'popularity'}, inplace=True)
```

### 修改所有列名

```python
df.columns = ['col1', 'col2', 'col3']
```


### 交换两列的位置

```python
df = df[df.columns[[1,0]]]
df = df.iloc[:,[2,1,0]]
```


### 修改类别数据的值
```python
# Convert the raw grades to a categorical data type
df["grade"] = df["raw_grade"].astype("category")
# Convert the raw grades to a categorical data type
df["grade"].cat.categories = ["very good", "good", "very bad"]
# Reorder the categories and simultaneously add the missing categories
df["grade"] = df["grade"].cat.set_categories(
     ["very bad", "bad", "medium", "good", "very good"]
 )
```


### 修改数据类型

```python
df['salary_avg'] = df['salary_avg'].astype(np.float64)
```


### 修改数值列的格式

```python
# 创建一列一科学计数的dataframe
df = pd.DataFrame(np.random.random(10)**10, columns=['data'])
# 转换为保留3位小数
df.round(3)
# 转换为百分数
df.style.format({'data': '{0:.2%}'.format})
```


### 年月日错误处理

有日期数据错误，如下：

.. image:: https://github.com/szj2ys/deal_with_the_tasks_and_challenges/raw/main/datasets/resources/century_bug.png

```python
def fix_century(x):
    year = x.year - 100 if x.year > 1989 else x.year
    return datetime.date(year, x.month, x.day)

# apply the function fix_century on the column and replace the values to the right ones
df['Yr_Mo_Dy'] = df['Yr_Mo_Dy'].apply(fix_century)
```


.. image:: https://github.com/szj2ys/deal_with_the_tasks_and_challenges/raw/main/datasets/resources/century_bug_fixed.png




## 增加

### 增加一列
```python
df.loc[:, "rank_index"] = range(1, len(df) + 1)
```



## 合并

### `education`列和`salary_avg`列合并，只有str类型才行

```python
df['edu_sal'] = df['education'] + df['salary_avg'].astype(str)
```

### 将两列数据合并成一列数据

```python
# 两个str列相加操作是拼接，两个数值列可以进行算数操作
df['test'] = df['education']+df['createTime'].map(str)
```

## 拆分

### 将list拆分成行
```python
df['sentence'] = df['sentence'].apply(lambda x: x.split(";"))
df['sentence'] = df.explode('sentence').drop_duplicates().reset_index(drop=True)
```


## 提取


### Airline列，有一些多余的标点符号，需要提取出正确的航司名称。举例：'(British Airways. )' 应该改为 'British Airways'

```python
df['Airline'] = df['Airline'].str.extract('([a-zA-Z\s]+)', expand=False).str.strip()
```

### 抽取地名
```python
df = pd.DataFrame({
    "name":["Tom-male","Peter male","Jimmy-female","Mike male","John-female"],
    "address":["广东省深圳市","广东省广州市","浙江省杭州市","江苏省南京市","湖南省长沙市"]}
    )
    
# 提取省份
df['address'].str.extract(r'(.*?)省', expand=True)  # expand：是否把结果转成Dataframe

# 提取省份+城市
df['address'].str.extract(r'(?P<Province>.*?)省(?P<City>.*?)市', expand=True)

# 提取名字+性别
df['name'].str.extract(r'(?P<姓名>[\w]+).*?(?P<性别>\w+)', expand=True)
```

### `RecentDelays`列，数据被以列表的形式录入，但是我们希望每个数字被录入成单独一列，delay_1, delay_2, ...没有的用NAN替代

```python
delays = df['RecentDelays'].apply(pd.Series)
delays.columns = ['delay_{}'.format(n) for n in range(1, len(delays.columns)+1)]
df = df.drop('RecentDelays', axis=1).join(delays)
```



## 分段


### 新增一列根据salary_avg将数据分组

```python
bins = [0,14000,17500,25000,45000]
labels = ['低', '中', '高', '很高']
df['categories'] = pd.cut(df.salary_avg, bins=bins, labels=labels)
```




## 缺失值处理

### 时间序列缺失值填充
```python
df.interpolate(method="time")
```

### 缺失值填充

```python
'''
method: time, values, spline, polynomial, barycentric, pchip, akima, linear
limit_direction: both, forward, backward
limit_area: outside, inside
'''
df.interpolate(method='linear', limit_direction='forward', axis=0)
```

### 将空值用上下值的平均值填充

```python
df['popularity'].fillna(df['popularity'].interpolate(), inplace=True)
dff.fillna(dff.mean())
dff.fillna(dff.mean()["B":"C"])  # 只对选择的B、C两列做fillna
df.fillna(value=5, inplace=True)
```

### 把被错误填充的缺失值还原

我们可以对缺失值进行丢弃处理，但是这种操作往往会丢失了很多信息的，很多时候我们都需要先看看缺失的原因，如果有些缺失是正常存在的，我们就不需要进行丢弃，保留着对我们的模型其实帮助会更大的。

此外，还有一种情况就是我们直接进行统计，它是没有缺失的，但是实际上是缺失的，什么意思？就是说缺失被人为（系统）地进行了填充，比如我们常见的用0、-9、-999、blank等来进行填充缺失，若真遇见这种情况，我们可以这么处理呢？

很简单，那就是**还原缺失！**

#### 单个操作

```python
# 引入数据集(皮马印第安人糖尿病预测数据集)
pima_columns = ['times_pregment','plasma_glucose_concentration','diastolic_blood_pressure','triceps_thickness',
                'serum_insulin','bmi','pedigree_function','age','onset_disbetes']

pima = pd.read_csv('./data/pima.data', names=pima_columns)


# 处理被错误填充的缺失值0，还原为 空(单独处理)
pima['serum_insulin'] = pima['serum_insulin'].map(lambda x:x if x !=0 else None)
# 检查变量缺失情况
pima['serum_insulin'].isnull().sum()

# Output：374
```

#### 批量操作

```python
# 批量操作 还原缺失值
columns = ['serum_insulin','bmi','plasma_glucose_concentration','diastolic_blood_pressure','triceps_thickness']

for col in columns:
    pima[col].replace([0], [None], inplace=True)

# 检查变量缺失情况
pima.isnull().sum()
```


## 删除

### 删除数值重复的行

```python
df.drop_duplicates(ignore_index=True, subset='grammer')
```

### 删除最后一行数据

```python
df.drop(len(df)-1, inplace=True)
```

### 删除行
```python
# 默认参数axis=0，根据索引(index)删除指定的行，删除第0行数据
df.drop(0)
```

### 删除列
```python
# axis=1,根据列名(columns)删除指定的列，删除'dt'列
df.drop('dt',axis=1)
```

### 删除所有缺失的行

```python
'''
备注
axis：0-行操作（默认），1-列操作
how：any-只要有空值就删除（默认），all-全部为空值才删除
inplace：False-返回新的数据集（默认），True-在原数据集上操作
'''
df.dropna(axis=0, how='any', inplace=True)
df["one"].dropna()
```





### 删除`categories`列

```python
df.drop('categories', axis=1, inplace=True)
```


### 删除所有`换手率(%)`非数字的行

```python
# 根据正则拿出所有非数字的行的下标  删除对应下标所在的行
df.drop(df[df['换手率(%)'].apply(lambda x :len(re.findall('^[0-9]+(\.?[0-9]+)?$', str(x))))<1].index, axis=0)
```

### 按字符串长度过滤
```python
# 选取searchkey字符串长度大于1的数据
df = df[df.searchkey.apply(lambda x: len(str(x)) >1)]
```










